{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNPjtk3dEm/lfZ7bTps9hfv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Import Libraries\n","In this cell, we import necessary libraries for our task. TensorFlow and Keras are used for model building and training. Matplotlib and Seaborn are used for data visualization. Numpy is used for numerical operations. Sklearn metrics are used for model evaluation.\n"],"metadata":{"id":"vjcMGfYeeyif"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"31cN_KXwJnwW","executionInfo":{"status":"ok","timestamp":1706336651764,"user_tz":-180,"elapsed":4935,"user":{"displayName":"Dedan Okware","userId":"16669846159449942480"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","from sklearn.metrics import classification_report, confusion_matrix\n"]},{"cell_type":"markdown","source":["# Load and Preprocess the Dataset\n","In this cell, we load the CIFAR-10 dataset, which is a standard dataset for image classification in the field of machine learning. We also normalize the images and convert the labels to one-hot encoded vectors for training.\n","\n"],"metadata":{"id":"1WGYttPHkZwD"}},{"cell_type":"code","source":["# Load CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","\n","# Normalize pixel values to be between 0 and 1\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","# Convert class vectors to binary class matrices (one-hot encoding)\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wozjVUx6kcvS","executionInfo":{"status":"ok","timestamp":1706336664355,"user_tz":-180,"elapsed":7482,"user":{"displayName":"Dedan Okware","userId":"16669846159449942480"}},"outputId":"862bef87-c1be-4e95-e9f6-f646b696d0ea"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 4s 0us/step\n"]}]},{"cell_type":"markdown","source":["# Data Augmentation\n","To improve the model's ability to generalize, we apply data augmentation techniques such as random rotation, width and height shift, horizontal flip, and zoom on the training data.\n"],"metadata":{"id":"k4K7hT37mI7A"}},{"cell_type":"code","source":["# Data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    zoom_range=0.2\n",")\n","\n","datagen.fit(x_train)\n"],"metadata":{"id":"aB7n-CimmLYN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build the CNN Model\n","Here, we construct a Convolutional Neural Network (CNN) using Keras. The model includes convolutional layers, max pooling layers, dropout layers for regularization, and a fully connected layer for classification.\n"],"metadata":{"id":"2NFjtXWsmN4e"}},{"cell_type":"code","source":["# Build the CNN model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n","    MaxPooling2D((2, 2)),\n","    Dropout(0.25),\n","\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Dropout(0.25),\n","\n","    Conv2D(128, (3, 3), activation='relu'),\n","    Flatten(),\n","    Dropout(0.5),\n","    Dense(10, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"SOMBw5WFmQDN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train the Model\n","In this cell, we train the CNN model using the training data. We use the augmented data generator for training and set aside a portion of the training data for validation.\n"],"metadata":{"id":"5JSI3PUrmR1P"}},{"cell_type":"code","source":["# Train the model\n","history = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n","                    steps_per_epoch=len(x_train) / 32, epochs=10,\n","                    validation_data=(x_test, y_test))\n"],"metadata":{"id":"5d7EZyYGmT3b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate the Model\n","We evaluate the model's performance on the test dataset and display the accuracy and loss during training and validation. We also use a confusion matrix and classification report for detailed evaluation.\n"],"metadata":{"id":"PSSAPPKomWXc"}},{"cell_type":"code","source":["# Plot training & validation accuracy and loss\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Model Accuracy')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Model Loss')\n","plt.legend()\n","plt.show()\n","\n","# Confusion Matrix and Classification Report\n","y_pred = model.predict(x_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true = np.argmax(y_test, axis=1)\n","\n","cm = confusion_matrix(y_true, y_pred_classes)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.show()\n","\n","print('Classification Report:')\n","print(classification_report(y_true, y_pred_classes))\n"],"metadata":{"id":"gT4PYfm6mYNh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save the Model\n","Finally, we save the trained model for future use. This allows us to load the model later and use it for predictions without needing to retrain it.\n"],"metadata":{"id":"mm_K9v7tmaQf"}},{"cell_type":"code","source":["# Save the trained model\n","model.save('cifar10_cnn_model.h5')"],"metadata":{"id":"guwm-Nw_mc8K"},"execution_count":null,"outputs":[]}]}